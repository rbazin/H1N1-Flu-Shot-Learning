{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'objectif est de construire un modèle englobant des modèles plus simples pour améliorer les résultats globaux par un système de soft voting.\n",
    "Modèles à utiliser :\n",
    "* DeepLearning\n",
    "* RandomForest\n",
    "* XGB\n",
    "* AdaBoost\n",
    "* LogisticRegression\n",
    "* AutoFeat ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports and functions\n",
    "========"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from autofeat import AutoFeatClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import reciprocal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def numerical_impute(data, numerical_list):\n",
    "    imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "    data_numerical = data.loc[:, numerical_list]\n",
    "    data_numerical_imputed = imputer_numerical.fit_transform(data_numerical)\n",
    "    data_numerical_imputed = pd.DataFrame(data_numerical_imputed, columns=numerical_list)\n",
    "    return data_numerical_imputed\n",
    "\n",
    "def categorical_imputing(data, categorical_list):\n",
    "    # Imputing\n",
    "    imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "    data_categorical = data.loc[:, categorical_list]\n",
    "    data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "    data_categorical_imputed = pd.DataFrame(data_categorical, columns=categorical_list)\n",
    "    return data_categorical_imputed\n",
    "\n",
    "def categorical_impute_one_hot(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # One hot encoding\n",
    "    data_one_hot = pd.get_dummies(data_categorical_imputed)\n",
    "\n",
    "    return data_one_hot\n",
    "\n",
    "def categorical_impute_ordinal(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_ordinal = ordinal_encoder.fit_transform(data_categorical_imputed)\n",
    "    data_ordinal = pd.DataFrame(data_ordinal, columns=categorical_list)\n",
    "\n",
    "    return data_ordinal\n",
    "\n",
    "def data_clean(data, numerical_list, categorical_list, encoding='one_hot'):\n",
    "    # Changer les listes de features et les fonctions correspondantes\n",
    "    if encoding == 'ordinal':\n",
    "        data_categorical_encoded = categorical_impute_ordinal(data, categorical_list)\n",
    "    else :\n",
    "        data_categorical_encoded = categorical_impute_one_hot(data, categorical_list)\n",
    "    data_numerical_imputed = numerical_impute(data, numerical_list)\n",
    "    data_imputed_encoded = pd.merge(data_numerical_imputed, data_categorical_encoded, left_index=True, right_index=True)\n",
    "\n",
    "    return data_imputed_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data prep\n",
    "======="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "FEATURES_TRAINING_PATH = \"training_set_features.csv\"\n",
    "LABELS_TRAINING_PATH = \"training_set_labels.csv\"\n",
    "\n",
    "features = pd.read_csv(FEATURES_TRAINING_PATH, sep=\",\", header=0)\n",
    "labels = pd.read_csv(LABELS_TRAINING_PATH, sep=\",\", header=0)\n",
    "data_original = pd.merge(features, labels, on=\"respondent_id\")\n",
    "respondent_id = data_original.loc[:, ['respondent_id']]\n",
    "data_original.drop(\"respondent_id\", axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data = data_original.copy()\n",
    "arg_list = list(data.keys())\n",
    "features_list = arg_list.copy()\n",
    "features_list.remove(\"h1n1_vaccine\")\n",
    "features_list.remove(\"seasonal_vaccine\")\n",
    "\n",
    "labels_list = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "\n",
    "categorical_list = ['age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa','employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_one_hot = ['race', 'sex', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 'employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_ordinal = [k for k in categorical_list if k not in categorical_list_one_hot]\n",
    "\n",
    "numerical_list = [k for k in features_list if k not in categorical_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_encoded = data_clean(data, numerical_list, categorical_list, encoding='one_hot')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "labels.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "Y = labels.to_numpy()\n",
    "X = data_encoded.to_numpy()\n",
    "\n",
    "shape_train_data = X.shape[1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size=0.2)\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=1, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Maintenant X contient les données scaled et encodées par one hot et Y les deux labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrainnement des modèles qui constitueront l'ensemble\n",
    "==============="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RandomForest\n",
    "--------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators' : [30, 100, 300, 500],\n",
    "    'max_features' : [4, 8, 12],\n",
    "    'max_leaf_nodes' : [2, 4, 6]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n             param_grid={'max_features': [4, 8, 12],\n                         'max_leaf_nodes': [2, 4, 6],\n                         'n_estimators': [30, 100, 300, 500]},\n             return_train_score=True, scoring='neg_mean_squared_error')"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndf_clf = RandomForestClassifier()\n",
    "grid_rndf = GridSearchCV(rndf_clf, param_grid=params, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "grid_rndf.fit(X_train_scaled, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_features': 8, 'max_leaf_nodes': 6, 'n_estimators': 300}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rndf.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8285420134411676"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_test_pred = grid_rndf.predict_proba(X_test_scaled)\n",
    "h1n1_grid_pred = grid_test_pred[0][:, 1]\n",
    "seasonal_grid_pred = grid_test_pred[1][:, 1]\n",
    "grid_pred = np.c_[h1n1_grid_pred, seasonal_grid_pred]\n",
    "roc_auc_score(Y_test, grid_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier()"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier()\n",
    "rnd_clf.fit(X_train_scaled, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8574289911081037"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_test_pred = rnd_clf.predict_proba(X_test_scaled)\n",
    "h1n1_pred = rnd_test_pred[0][:,1]\n",
    "seasonal_pred = rnd_test_pred[1][:,1]\n",
    "rnd_test_pred = np.c_[h1n1_pred, seasonal_pred]\n",
    "roc_auc_score(Y_test, rnd_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.857 (sans grid search et CV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romai\\documents\\projets\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n              gamma=0, gpu_id=-1, importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=8,\n              num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_h1n1 = XGBClassifier()\n",
    "xgb_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romai\\documents\\projets\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n              gamma=0, gpu_id=-1, importance_type=None,\n              interaction_constraints='', learning_rate=0.300000012,\n              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n              monotone_constraints='()', n_estimators=100, n_jobs=8,\n              num_parallel_tree=1, predictor='auto', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_seasonal = XGBClassifier()\n",
    "xgb_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8586314822015296"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_h1n1_pred = xgb_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "xgb_clf_seasonal_pred = xgb_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "xgb_pred = np.c_[xgb_clf_h1n1_pred, xgb_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, xgb_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.858"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AdaBoost\n",
    "------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "AdaBoostClassifier()"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_h1n1 = AdaBoostClassifier()\n",
    "ada_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "AdaBoostClassifier()"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_seasonal = AdaBoostClassifier()\n",
    "ada_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8637746854415985"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_h1n1_pred = ada_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "ada_clf_seasonal_pred = ada_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "ada_pred = np.c_[ada_clf_h1n1_pred, ada_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, ada_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.864"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CatBoost\n",
    "--------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x2126975fb80>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_h1n1 = CatBoostClassifier()\n",
    "cb_clf_h1n1.fit(X_train_scaled, Y_train[:, 0], verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostClassifier at 0x2126975fdf0>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_seasonal = CatBoostClassifier()\n",
    "cb_clf_seasonal.fit(X_train_scaled, Y_train[:, 1], verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8710041487146035"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_h1n1_pred = cb_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "cb_clf_seasonal_pred = cb_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "cb_pred = np.c_[cb_clf_h1n1_pred, cb_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, cb_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.871"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LogisticRegression\n",
    "--------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Se renseigner sur le paramètres \"multinomial\" ?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_h1n1 = LogisticRegression()\n",
    "lr_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_seasonal = LogisticRegression()\n",
    "lr_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8550356336880862"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_h1n1_pred = lr_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_clf_seasonal_pred = lr_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_pred = np.c_[lr_clf_h1n1_pred, lr_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, lr_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.855"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVC\n",
    "------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut surement largement améliorer la prédiction en utilisant les kernel polynomiaux. Il faudrait faire un tuning du degré des polys pour optimiser les prédictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(probability=True)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_h1n1 = SVC(probability=True, kernel=\"poly\", degree=3)\n",
    "svc_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(probability=True)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_seasonal = SVC(probability=True, kernel=\"poly\", degree=3)\n",
    "svc_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8502236838526532"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_h1n1_pred = svc_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "svc_clf_seasonal_pred = svc_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "svc_pred = np.c_[svc_clf_h1n1_pred, svc_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, svc_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.850"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DeepLearning\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "dl_clf = keras.models.load_model(\"best_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8594474913605683"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_clf_pred = dl_clf.predict(X_test_scaled)\n",
    "roc_auc_score(Y_test, dl_clf_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ROCAUC score : 0.859"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "AutoFeat\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "af_clf = joblib.load(\"autoFeatModel.save\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il faut transformer les données pour que AutoFeat fonctionne"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "af_clf_h1n1_pred = af_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 0], af_clf_h1n1_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble\n",
    "======"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble learning for 'h1n1_vaccine' label\n",
    "---------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We test ensemble learning just for 'h1n1_vaccine'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that all of our models are built (even though I didn't take the time to optimize them with CrossValidation), we can gather them into one algorithm thanks to the power of soft voting.\n",
    "On peut mettre des pipelines plutot que des algos dans les estimateurs et je crois que le type d'estimateur n'a pas d'importance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "lr_clf_h1n1 = LogisticRegression()\n",
    "rndf_clf_h1n1 = RandomForestClassifier()\n",
    "xgb_clf_h1n1 = XGBClassifier()\n",
    "ada_clf_h1n1 = AdaBoostClassifier()\n",
    "cb_clf_h1n1 = CatBoostClassifier()\n",
    "svc_clf_h1n1 = SVC(probability=True, kernel=\"poly\", degree=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Soft voting classifier :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('lr', LogisticRegression()),\n                             ('rndf', RandomForestClassifier()),\n                             ('xgb',\n                              XGBClassifier(base_score=None, booster=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=None,\n                                            enable_categorical=False,\n                                            gamma=None, gpu_id=None,\n                                            importance_type=None,\n                                            interaction_constraints=None,\n                                            learning_rate=None,\n                                            max_delta_step=None, max_d...\n                                            num_parallel_tree=None,\n                                            predictor=None, random_state=None,\n                                            reg_alpha=None, reg_lambda=None,\n                                            scale_pos_weight=None,\n                                            subsample=None, tree_method=None,\n                                            validate_parameters=None,\n                                            verbosity=None)),\n                             ('ada', AdaBoostClassifier()),\n                             ('cb',\n                              <catboost.core.CatBoostClassifier object at 0x0000025D984F5AC0>),\n                             ('svc', SVC(kernel='poly', probability=True))],\n                 n_jobs=-1, verbose=True, voting='soft')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_clf_h1n1),\n",
    "        ('rndf', rndf_clf_h1n1),\n",
    "        ('xgb', xgb_clf_h1n1),\n",
    "        ('ada', ada_clf_h1n1),\n",
    "        ('cb', cb_clf_h1n1),\n",
    "        ('svc', svc_clf_h1n1),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    verbose=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "vote_clf_h1n1.fit(X_train_scaled, Y_train[:, 0]) # On entraine le modèle ensembliste sur le label 'h1n1_vaccine'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultat sur le set d'entrainnement :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9823358426198993"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1_pred = vote_clf_h1n1.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_train[:, 0], vote_clf_h1n1_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultat sur le set de test (sans optimisation des params) :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8733484130403563"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1_pred = vote_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 0], vote_clf_h1n1_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ensemble learning for 'seasonal_vaccine' label\n",
    "-----------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We test ensemble learning just for 'h1n1_vaccine'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "lr_clf_seasonal = LogisticRegression()\n",
    "rndf_clf_seasonal = RandomForestClassifier()\n",
    "xgb_clf_seasonal = XGBClassifier()\n",
    "ada_clf_seasonal = AdaBoostClassifier()\n",
    "cb_clf_seasonal = CatBoostClassifier()\n",
    "svc_clf_seasonal = SVC(probability=True, kernel=\"poly\", degree=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Soft voting classifier :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('lr', LogisticRegression()),\n                             ('rndf', RandomForestClassifier()),\n                             ('xgb',\n                              XGBClassifier(base_score=None, booster=None,\n                                            colsample_bylevel=None,\n                                            colsample_bynode=None,\n                                            colsample_bytree=None,\n                                            enable_categorical=False,\n                                            gamma=None, gpu_id=None,\n                                            importance_type=None,\n                                            interaction_constraints=None,\n                                            learning_rate=None,\n                                            max_delta_step=None, max_d...\n                                            num_parallel_tree=None,\n                                            predictor=None, random_state=None,\n                                            reg_alpha=None, reg_lambda=None,\n                                            scale_pos_weight=None,\n                                            subsample=None, tree_method=None,\n                                            validate_parameters=None,\n                                            verbosity=None)),\n                             ('ada', AdaBoostClassifier()),\n                             ('cb',\n                              <catboost.core.CatBoostClassifier object at 0x0000025D984EE280>),\n                             ('svc', SVC(kernel='poly', probability=True))],\n                 n_jobs=-1, verbose=True, voting='soft')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_clf_seasonal),\n",
    "        ('rndf', rndf_clf_seasonal),\n",
    "        ('xgb', xgb_clf_seasonal),\n",
    "        ('ada', ada_clf_seasonal),\n",
    "        ('cb', cb_clf_seasonal),\n",
    "        ('svc', svc_clf_seasonal),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    verbose=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "vote_clf_seasonal.fit(X_train_scaled, Y_train[:, 1]) # On entraine le modèle ensembliste sur le label 'seasonal_vaccine'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultat sur le set d'entrainnement :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9681467453726371"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal_pred = vote_clf_seasonal.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_train[:, 1], vote_clf_seasonal_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultat sur le set de test (sans optimisation des params) :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8672901476944609"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal_pred = vote_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 1], vote_clf_seasonal_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Merging of the two models\n",
    "-------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8703192803674086"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.c_[vote_clf_h1n1_pred, vote_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultat après fusion : 87 % sans optimisation des paramètres de chaque modèle."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Points d'amélioration :\n",
    "* Optimisation des paramètres de chaque modèle et cross validation.\n",
    "* Réessayer les modèles avec les paramètres générés par autofeat (pour l'instant seulement pour 'h1n1_vaccine').\n",
    "* Essayer d'entrainer un modèle remplaçant le soft voting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}