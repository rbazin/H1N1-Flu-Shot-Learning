{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "L'objectif est de construire un modèle englobant des modèles plus simples pour améliorer les résultats globaux par un système de soft voting.\n",
    "Modèles à utiliser :\n",
    "* DeepLearning\n",
    "* RandomForest\n",
    "* XGB\n",
    "* AdaBoost\n",
    "* LogisticRegression\n",
    "* AutoFeat ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports and functions\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from autofeat import AutoFeatClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_impute(data, numerical_list):\n",
    "    imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "    data_numerical = data.loc[:, numerical_list]\n",
    "    data_numerical_imputed = imputer_numerical.fit_transform(data_numerical)\n",
    "    data_numerical_imputed = pd.DataFrame(data_numerical_imputed, columns=numerical_list)\n",
    "    return data_numerical_imputed\n",
    "\n",
    "def categorical_imputing(data, categorical_list):\n",
    "    # Imputing\n",
    "    imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "    data_categorical = data.loc[:, categorical_list]\n",
    "    data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "    data_categorical_imputed = pd.DataFrame(data_categorical, columns=categorical_list)\n",
    "    return data_categorical_imputed\n",
    "\n",
    "def categorical_impute_one_hot(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # One hot encoding\n",
    "    data_one_hot = pd.get_dummies(data_categorical_imputed)\n",
    "\n",
    "    return data_one_hot\n",
    "\n",
    "def categorical_impute_ordinal(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_ordinal = ordinal_encoder.fit_transform(data_categorical_imputed)\n",
    "    data_ordinal = pd.DataFrame(data_ordinal, columns=categorical_list)\n",
    "\n",
    "    return data_ordinal\n",
    "\n",
    "def data_clean(data, numerical_list, categorical_list, encoding='one_hot'):\n",
    "    # Changer les listes de features et les fonctions correspondantes\n",
    "    if encoding == 'ordinal':\n",
    "        data_categorical_encoded = categorical_impute_ordinal(data, categorical_list)\n",
    "    else :\n",
    "        data_categorical_encoded = categorical_impute_one_hot(data, categorical_list)\n",
    "    data_numerical_imputed = numerical_impute(data, numerical_list)\n",
    "    data_imputed_encoded = pd.merge(data_numerical_imputed, data_categorical_encoded, left_index=True, right_index=True)\n",
    "\n",
    "    return data_imputed_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data prep\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES_TRAINING_PATH = \"training_set_features.csv\"\n",
    "LABELS_TRAINING_PATH = \"training_set_labels.csv\"\n",
    "\n",
    "features = pd.read_csv(FEATURES_TRAINING_PATH, sep=\",\", header=0)\n",
    "labels = pd.read_csv(LABELS_TRAINING_PATH, sep=\",\", header=0)\n",
    "data_original = pd.merge(features, labels, on=\"respondent_id\")\n",
    "respondent_id = data_original.loc[:, ['respondent_id']]\n",
    "data_original.drop(\"respondent_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data_original.copy()\n",
    "arg_list = list(data.keys())\n",
    "features_list = arg_list.copy()\n",
    "features_list.remove(\"h1n1_vaccine\")\n",
    "features_list.remove(\"seasonal_vaccine\")\n",
    "\n",
    "labels_list = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "\n",
    "categorical_list = ['age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa','employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_one_hot = ['race', 'sex', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 'employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_ordinal = [k for k in categorical_list if k not in categorical_list_one_hot]\n",
    "\n",
    "numerical_list = [k for k in features_list if k not in categorical_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded = data_clean(data, numerical_list, categorical_list, encoding='one_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "Y = labels.to_numpy()\n",
    "X = data_encoded.to_numpy()\n",
    "\n",
    "shape_train_data = X.shape[1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size=0.2)\n",
    "# X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Maintenant X contient les données scaled et encodées par one hot et Y les deux labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Entrainnement des modèles qui constitueront l'ensemble\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "RandomForest\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators' : [30, 100, 300, 500],\n",
    "    'max_features' : [4, 8, 12],\n",
    "    'max_leaf_nodes' : [2, 4, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': [4, 8, 12],\n",
       "                         'max_leaf_nodes': [2, 4, 6],\n",
       "                         'n_estimators': [30, 100, 300, 500]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndf_clf = RandomForestClassifier()\n",
    "grid_rndf = GridSearchCV(rndf_clf, param_grid=params, cv=5, scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "grid_rndf.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'max_leaf_nodes': 6, 'n_estimators': 300}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rndf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8285420134411676"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_test_pred = grid_rndf.predict_proba(X_test_scaled)\n",
    "h1n1_grid_pred = grid_test_pred[0][:, 1]\n",
    "seasonal_grid_pred = grid_test_pred[1][:, 1]\n",
    "grid_pred = np.c_[h1n1_grid_pred, seasonal_grid_pred]\n",
    "roc_auc_score(Y_test, grid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier()\n",
    "rnd_clf.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574289911081037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_test_pred = rnd_clf.predict_proba(X_test_scaled)\n",
    "h1n1_pred = rnd_test_pred[0][:,1]\n",
    "seasonal_pred = rnd_test_pred[1][:,1]\n",
    "rnd_test_pred = np.c_[h1n1_pred, seasonal_pred]\n",
    "roc_auc_score(Y_test, rnd_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.857 (sans grid search et CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "XGBoost\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romai\\documents\\projets\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:05:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_h1n1 = XGBClassifier()\n",
    "xgb_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romai\\documents\\projets\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_seasonal = XGBClassifier()\n",
    "xgb_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8586314822015296"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf_h1n1_pred = xgb_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "xgb_clf_seasonal_pred = xgb_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "xgb_pred = np.c_[xgb_clf_h1n1_pred, xgb_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "AdaBoost\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_h1n1 = AdaBoostClassifier()\n",
    "ada_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_seasonal = AdaBoostClassifier()\n",
    "ada_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8637746854415985"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf_h1n1_pred = ada_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "ada_clf_seasonal_pred = ada_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "ada_pred = np.c_[ada_clf_h1n1_pred, ada_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, ada_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.864"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "CatBoost\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2126975fb80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_h1n1 = CatBoostClassifier()\n",
    "cb_clf_h1n1.fit(X_train_scaled, Y_train[:, 0], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2126975fdf0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_seasonal = CatBoostClassifier()\n",
    "cb_clf_seasonal.fit(X_train_scaled, Y_train[:, 1], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710041487146035"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_clf_h1n1_pred = cb_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "cb_clf_seasonal_pred = cb_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "cb_pred = np.c_[cb_clf_h1n1_pred, cb_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, cb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.871"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LogisticRegression\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Se renseigner sur le paramètres \"multinomial\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_h1n1 = LogisticRegression()\n",
    "lr_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_seasonal = LogisticRegression()\n",
    "lr_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550356336880862"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf_h1n1_pred = lr_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_clf_seasonal_pred = lr_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "lr_pred = np.c_[lr_clf_h1n1_pred, lr_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SVC\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On peut surement largement améliorer la prédiction en utilisant les kernel polynomiaux. Il faudrait faire un tuning du degré des polys pour optimiser les prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_h1n1 = SVC(probability=True, kernel=\"poly\", degree=3)\n",
    "svc_clf_h1n1.fit(X_train_scaled, Y_train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_seasonal = SVC(probability=True, kernel=\"poly\", degree=3)\n",
    "svc_clf_seasonal.fit(X_train_scaled, Y_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502236838526532"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf_h1n1_pred = svc_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "svc_clf_seasonal_pred = svc_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "svc_pred = np.c_[svc_clf_h1n1_pred, svc_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, svc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "DeepLearning\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dl_clf = keras.models.load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594474913605683"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_clf_pred = dl_clf.predict(X_test_scaled)\n",
    "roc_auc_score(Y_test, dl_clf_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ROCAUC score : 0.859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "AutoFeat\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "af_clf = joblib.load(\"autoFeatModel.save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Il faut transformer les données pour que AutoFeat fonctionne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "af_clf_h1n1_pred = af_clf.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 0], af_clf_h1n1_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ensemble\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ensemble learning for 'h1n1_vaccine' label\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On teste avec les données de autofeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "X = pd.read_csv(\"new_features_train.csv\", sep=\",\", header=0) # Features generated with autofeat module for h1n1_vaccine prediction\n",
    "Y = pd.read_csv(\"training_set_labels.csv\", sep=\",\", header=0)\n",
    "Y.drop(\"respondent_id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We test ensemble learning just for 'h1n1_vaccine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that all of our models are built (even though I didn't take the time to optimize them with CrossValidation), we can gather them into one algorithm thanks to the power of soft voting.\n",
    "On peut mettre des pipelines plutot que des algos dans les estimateurs et je crois que le type d'estimateur n'a pas d'importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf_h1n1 = LogisticRegression()\n",
    "rndf_clf_h1n1 = RandomForestClassifier()\n",
    "xgb_clf_h1n1 = XGBClassifier()\n",
    "ada_clf_h1n1 = AdaBoostClassifier()\n",
    "cb_clf_h1n1 = CatBoostClassifier()\n",
    "svc_clf_h1n1 = SVC(probability=True, kernel=\"poly\", degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Soft voting classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rndf', RandomForestClassifier()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_d...\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('ada', AdaBoostClassifier()),\n",
       "                             ('cb',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x0000018EB588C7C0>),\n",
       "                             ('svc', SVC(kernel='poly', probability=True))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_clf_h1n1),\n",
    "        ('rndf', rndf_clf_h1n1),\n",
    "        ('xgb', xgb_clf_h1n1),\n",
    "        ('ada', ada_clf_h1n1),\n",
    "        ('cb', cb_clf_h1n1),\n",
    "        ('svc', svc_clf_h1n1),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    verbose=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "vote_clf_h1n1.fit(X_train_scaled, Y_train[:, 0]) # On entraine le modèle ensembliste sur le label 'h1n1_vaccine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Résultat sur le set d'entrainnement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822816174863434"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1_pred = vote_clf_h1n1.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_train[:, 0], vote_clf_h1n1_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Résultat sur le set de test (sans optimisation des params) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8728837722077198"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_h1n1_pred = vote_clf_h1n1.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 0], vote_clf_h1n1_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Résultat avec les nouvelles features d'autofeat : 87.7 %, sans on était à 87,3 % !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On peut encore s'améliorer en optimisant les paramètres de chaque modèle et évidemment en ajoutant le modèle d'autofeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ensemble learning for 'seasonal_vaccine' label\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We test ensemble learning just for 'h1n1_vaccine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr_clf_seasonal = LogisticRegression()\n",
    "rndf_clf_seasonal = RandomForestClassifier()\n",
    "xgb_clf_seasonal = XGBClassifier()\n",
    "ada_clf_seasonal = AdaBoostClassifier()\n",
    "cb_clf_seasonal = CatBoostClassifier()\n",
    "svc_clf_seasonal = SVC(probability=True, kernel=\"poly\", degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Soft voting classifier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rndf', RandomForestClassifier()),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_d...\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('ada', AdaBoostClassifier()),\n",
       "                             ('cb',\n",
       "                              <catboost.core.CatBoostClassifier object at 0x0000018EB58ABEE0>),\n",
       "                             ('svc', SVC(kernel='poly', probability=True))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', lr_clf_seasonal),\n",
    "        ('rndf', rndf_clf_seasonal),\n",
    "        ('xgb', xgb_clf_seasonal),\n",
    "        ('ada', ada_clf_seasonal),\n",
    "        ('cb', cb_clf_seasonal),\n",
    "        ('svc', svc_clf_seasonal),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    verbose=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "vote_clf_seasonal.fit(X_train_scaled, Y_train[:, 1]) # On entraine le modèle ensembliste sur le label 'seasonal_vaccine'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Résultat sur le set d'entrainnement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681968845773338"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal_pred = vote_clf_seasonal.predict_proba(X_train_scaled)[:, 1]\n",
    "roc_auc_score(Y_train[:, 1], vote_clf_seasonal_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Résultat sur le set de test (sans optimisation des params) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8669727760126383"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_clf_seasonal_pred = vote_clf_seasonal.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_score(Y_test[:, 1], vote_clf_seasonal_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86.6 % sans autofeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Merging of the two models\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869928274110179"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.c_[vote_clf_h1n1_pred, vote_clf_seasonal_pred]\n",
    "roc_auc_score(Y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Résultat après fusion (données sans autofeat) : 87 % sans optimisation des paramètres de chaque modèle.\n",
    "Résultat après fusion (données d'autofeat) : 87,3 % sans optimisation des paramètres de chaque modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Points d'amélioration :\n",
    "* Optimisation des paramètres de chaque modèle et cross validation.\n",
    "* Réessayer les modèles avec les paramètres générés par autofeat (pour l'instant seulement pour 'h1n1_vaccine').\n",
    "* Essayer d'entrainer un modèle remplaçant le soft voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sauvegarde des deux modèles d'ensemble prometteurs\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soft_voting_ensemble_seasonal.save']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vote_clf_h1n1, \"soft_voting_ensemble_h1n1.save\")\n",
    "joblib.dump(vote_clf_seasonal, \"soft_voting_ensemble_seasonal.save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Génération du csv de sortie avec les modèles d'ensemble\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:434: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"test_set_features.csv\", sep=\",\", header=0)\n",
    "respondent_id = test_data['respondent_id']\n",
    "test_data.drop('respondent_id', axis=1, inplace=True)\n",
    "X_test = data_clean(test_data, numerical_list, categorical_list, encoding='one_hot')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_h1n1 = vote_clf_h1n1.predict_proba(X_test)[:, 1]\n",
    "pred_seasonal = vote_clf_seasonal.predict_proba(X_test)[:, 1]\n",
    "pred = np.c_[pred_h1n1, pred_seasonal]\n",
    "pred_df = pd.DataFrame(pred, columns=['h1n1_vaccine', 'seasonal_vaccine'])\n",
    "res_df = pd.merge(respondent_id, pred_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26707</td>\n",
       "      <td>0.205885</td>\n",
       "      <td>0.362864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26708</td>\n",
       "      <td>0.135989</td>\n",
       "      <td>0.162853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26709</td>\n",
       "      <td>0.295734</td>\n",
       "      <td>0.626070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26710</td>\n",
       "      <td>0.605333</td>\n",
       "      <td>0.829401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26711</td>\n",
       "      <td>0.381831</td>\n",
       "      <td>0.491085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   respondent_id  h1n1_vaccine  seasonal_vaccine\n",
       "0          26707      0.205885          0.362864\n",
       "1          26708      0.135989          0.162853\n",
       "2          26709      0.295734          0.626070\n",
       "3          26710      0.605333          0.829401\n",
       "4          26711      0.381831          0.491085"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "res_df.to_csv(\"predictions_ensemble_withoutAutofeat.csv\", header=True, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Résultat réel avec autofeat : 83,67 % donc très décevant, surement trop d'overfitting mais peut être que ça vient des données d'autofeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat sans autofeat : 85,6 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
