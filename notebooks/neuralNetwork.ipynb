{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# H1N1 - Flu Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import reciprocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_impute(data, numerical_list):\n",
    "    imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "    data_numerical = data.loc[:, numerical_list]\n",
    "    data_numerical_imputed = imputer_numerical.fit_transform(data_numerical)\n",
    "    data_numerical_imputed = pd.DataFrame(data_numerical_imputed, columns=numerical_list)\n",
    "    return data_numerical_imputed\n",
    "\n",
    "def categorical_imputing(data, categorical_list):\n",
    "    # Imputing\n",
    "    imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "    data_categorical = data.loc[:, categorical_list]\n",
    "    data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "    data_categorical_imputed = pd.DataFrame(data_categorical, columns=categorical_list)\n",
    "    return data_categorical_imputed\n",
    "\n",
    "def categorical_impute_one_hot(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # One hot encoding\n",
    "    data_one_hot = pd.get_dummies(data_categorical_imputed)\n",
    "\n",
    "    return data_one_hot\n",
    "\n",
    "def categorical_impute_ordinal(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_ordinal = ordinal_encoder.fit_transform(data_categorical_imputed)\n",
    "    data_ordinal = pd.DataFrame(data_ordinal, columns=categorical_list)\n",
    "\n",
    "    return data_ordinal\n",
    "\n",
    "def categorical_impute_encode1(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_categorical_encoded = ordinal_encoder.fit_transform(data_categorical)\n",
    "    data_categorical_encoded = pd.DataFrame(data_categorical_encoded, columns=categorical_list)\n",
    "\n",
    "    return data_categorical_encoded\n",
    "\n",
    "def categorical_impute_encode2(data, categorical_list_one_hot, categorical_list_ordinal):\n",
    "    # Imputing\n",
    "    data_categorical = categorical_imputing(data, categorical_list_ordinal + categorical_list_one_hot)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_categorical_ordinal = ordinal_encoder.fit_transform(data_categorical.loc[:, categorical_list_ordinal])\n",
    "    data_categorical_ordinal = pd.DataFrame(data_categorical_ordinal, columns=categorical_list_ordinal)\n",
    "\n",
    "    # One hot encoding\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    data_categorical_one_hot = one_hot_encoder.fit_transform(data_categorical.loc[:, categorical_list_one_hot])\n",
    "    data_categorical_one_hot = pd.DataFrame(data_categorical_one_hot, columns=categorical_list_one_hot)\n",
    "\n",
    "    data_categorical_encoded = pd.merge(data_categorical_ordinal, data_categorical_one_hot, left_index=True, right_index=True)\n",
    "\n",
    "    return data_categorical_encoded\n",
    "\n",
    "def data_clean(data, numerical_list, categorical_list, encoding='one_hot'):\n",
    "    # Changer les listes de features et les fonctions correspondantes\n",
    "    if encoding == 'ordinal':\n",
    "        data_categorical_encoded = categorical_impute_ordinal(data, categorical_list)\n",
    "    else :\n",
    "        data_categorical_encoded = categorical_impute_one_hot(data, categorical_list)\n",
    "    data_numerical_imputed = numerical_impute(data, numerical_list)\n",
    "    data_imputed_encoded = pd.merge(data_numerical_imputed, data_categorical_encoded, left_index=True, right_index=True)\n",
    "    \n",
    "    return data_imputed_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import des données\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FEATURES_TRAINING_PATH = \"training_set_features.csv\"\n",
    "LABELS_TRAINING_PATH = \"training_set_labels.csv\"\n",
    "\n",
    "features = pd.read_csv(FEATURES_TRAINING_PATH, sep=\",\", header=0)\n",
    "labels = pd.read_csv(LABELS_TRAINING_PATH, sep=\",\", header=0)\n",
    "data_original = pd.merge(features, labels, on=\"respondent_id\")\n",
    "respondent_id = data_original.loc[:, ['respondent_id']]\n",
    "data_original.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "data = data_original.copy()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Liste des attributs\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arg_list = list(data.keys())\n",
    "features_list = arg_list.copy()\n",
    "features_list.remove(\"h1n1_vaccine\")\n",
    "features_list.remove(\"seasonal_vaccine\")\n",
    "\n",
    "labels_list = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "\n",
    "categorical_list = ['age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa','employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_one_hot = ['race', 'sex', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 'employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_ordinal = [k for k in categorical_list if k not in categorical_list_one_hot]\n",
    "\n",
    "numerical_list = [k for k in features_list if k not in categorical_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On sauvegarde les listes de label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fichier_sauvegarde_listes = 'lists.save'\n",
    "dic_label = {\n",
    "    'numerical_list' : numerical_list,\n",
    "    'categorical_list' : categorical_list,\n",
    "}\n",
    "joblib.dump(dic_label, fichier_sauvegarde_listes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lists = joblib.load(\"lists.save\")\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "data_categorical = data.loc[:, categorical_list]\n",
    "data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "data_categorical = pd.DataFrame(data_categorical, columns=categorical_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "data_categorical_encoded = ordinal_encoder.fit_transform(data_categorical)\n",
    "data_categorical_encoded = pd.DataFrame(data_categorical_encoded, columns=categorical_list)\n",
    "data_categorical_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "data_numerical = data.loc[:, numerical_list]\n",
    "data_numerical = imputer_numerical.fit_transform(data_numerical)\n",
    "data_numerical = pd.DataFrame(data_numerical, columns=numerical_list)\n",
    "data_numerical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded = pd.merge(data_numerical, data_categorical_encoded, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Deep learning classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modèle Simple\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On veut déterminer les probabilités d'appartenance à chaque classe : multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded = data_clean(data, numerical_list, categorical_list, encoding='one_hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "Y = labels.to_numpy()\n",
    "X = data_encoded.to_numpy()\n",
    "\n",
    "shape_train_data = X.shape[1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size=0.2)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On scale les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sauvegarde du scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(scaler, \"scaler.save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Modèle séquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_neurons = 35\n",
    "dropout = 0.4\n",
    "n_layers = 3\n",
    "learning_rate = 3e-3\n",
    "model_seq = Sequential()\n",
    "model_seq.add(Input(shape=shape_train_data))\n",
    "for layer in range(n_layers):\n",
    "    model_seq.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model_seq.add(Dropout(dropout))\n",
    "model_seq.add(Dense(2, activation=\"sigmoid\"))\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model_seq.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['AUC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Modèle fonctionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# modele assez performant : on peut modifier la structure en ajoutant une voie annexe par ex\n",
    "input_ = keras.layers.Input(shape=shape_train_data)\n",
    "hidden1 = keras.layers.Dense(35, activation=\"relu\")(input_)\n",
    "dropout1 = keras.layers.Dropout(0.5)(hidden1)\n",
    "hidden2 = keras.layers.Dense(15, activation=\"relu\")(dropout1)\n",
    "output = keras.layers.Dense(2, activation=\"sigmoid\")(hidden2)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On set up un callback de checkpoint et un early stopping :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Entrainnement du modèle séquentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history_seq = model_seq.fit(X_train_scaled, Y_train, batch_size=32, epochs=100, validation_data=(X_valid_scaled, Y_valid), callbacks=[checkpoint_cb, early_stopping_cb], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Entrainnement du modèle fonctionnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, epochs=100, validation_data=(X_valid_scaled, Y_valid), callbacks=[checkpoint_cb, early_stopping_cb], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On récupère le meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model_ever = keras.models.load_model(\"best_model_ever_8_12_2021.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = model_seq.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred_best = best_model_ever.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"model : \", roc_auc_score(Y_test, Y_pred)) # C'est la mesure utilisée par DrivenData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"best model : \", roc_auc_score(Y_test, Y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Yeahhhh score de 85,97% c'est top ! Objectif : 86.6%\n",
    "Malheureusement, le score sur driven data est moins important et vaut seulement 84.5%, donc il y a de la marge de progrès !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Points d'amélioration :\n",
    "* A voir si en enlevant des données manquantes on ne peut pas encore améliorer le score\n",
    "* Il faudrait essayer le feature engineering\n",
    "* On peut utiliser un OneHot encoder pour certaines données catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Fine tuning Neural Network Hyperparameters\n",
    "========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Possible to use :\n",
    "* RandomizedSearchCV from scikit learn with some wrapper\n",
    "* Keras tuner from tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scikeras and RandomizedSearchCV\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, hidden_layer_sizes=30, learning_rate=3e-3, input_shape=[35]):\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(hidden_layer_sizes, activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_cross_entropy\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras_model = KerasClassifier(build_model, epochs=100, callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden' : [0,1,2,3],\n",
    "    'hidden_layer_sizes' : list(range(1,100)),\n",
    "    'optimizer__learning_rate' : [3e-4, 3e-3, 3e-2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_model, param_distribs, n_iter=10, cv=3, scoring='roc_auc')\n",
    "rnd_search_cv.fit(X_train_scaled, Y_train, validation_data=(X_valid_scaled, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scikeras un peu chiant à utiliser et pas super bien documenté"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Keras Tuner\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationHyperModel(HyperModel):\n",
    "    \"\"\" Keras HyperModel applied to the classification model to put the search space together \"\"\"\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Defining the hyperparameters to thune\n",
    "        nb_layers = hp.Int('n_layers', min_value=1, max_value=15, step=1, default=3)\n",
    "        nb_neurons = hp.Int('n_neurons', min_value=10, max_value=300, default=30)\n",
    "        dropout_rate = hp.Float('rate', min_value=0, max_value=0.9, default=0.5, step=0.1)\n",
    "        learning_rate = hp.Float('learnin_rate', min_value=1e-4, max_value=1e-2, default=1e-3, sampling='LOG')\n",
    "\n",
    "        # Building the model structure\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=self.input_shape))\n",
    "        for layer in range(nb_layers):\n",
    "            model.add(Dense(units=nb_neurons, activation=\"relu\"))\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "        model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate), metrics=['AUC'])\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = ClassificationHyperModel(input_shape=shape_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=40,\n",
    "    objective=kt.Objective('val_auc', direction='max'),\n",
    "    executions_per_trial=2,\n",
    "    seed=1,\n",
    "    directory='Keras-tuning',\n",
    "    project_name='neuralNetwork'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tuner.search(X_train_scaled, Y_train, validation_split=0.2, epochs=40, callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show summary of the results\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = best_model.predict(X_test_scaled)\n",
    "print(roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_model.save('model_hypertunned.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Best three models after tunning\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, nb_layers, nb_neurons, dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    for layer in range(nb_layers):\n",
    "        model.add(Dense(units=nb_neurons, activation=\"relu\"))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate), metrics=['AUC'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_three_parameters = [\n",
    "    {\n",
    "        'nb_layers' : 4,\n",
    "        'nb_neurons' : 236,\n",
    "        'dropout_rate' : 0.3,\n",
    "        'learning_rate' : 0.0001341426\n",
    "    },\n",
    "    {\n",
    "        'nb_layers' : 1,\n",
    "        'nb_neurons' : 62,\n",
    "        'dropout_rate' : 0.2,\n",
    "        'learning_rate' : 0.00309826\n",
    "    },\n",
    "    {\n",
    "        'nb_layers' : 2,\n",
    "        'nb_neurons' : 178,\n",
    "        'dropout_rate' : 0.2,\n",
    "        'learning_rate' : 0.000412680\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_three_models = []\n",
    "for parameters in top_three_parameters:\n",
    "    best_three_models.append(create_model(shape_train_data, parameters['nb_layers'], parameters['nb_neurons'], parameters['dropout_rate'], parameters['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for model in best_three_models:\n",
    "    model.fit(X_train_scaled, Y_train, epochs=40, validation_data=(X_valid_scaled, Y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for model in best_three_models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    print(\"ROCAUC score : \", roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Résultats assez décevant, il fallait probablement utiliser plus de données pour commencer ou augmenter l'espace de recherche :\n",
    "\n",
    "Résultats obtenus pour 36 min de recherche :\n",
    "* ROCAUC score :  0.8043674994274905\n",
    "* ROCAUC score :  0.816739745544371\n",
    "* ROCAUC score :  0.8113774287104558\n",
    "\n",
    "La recherche s'est terminée par \"oracle triggered exit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a probablement beaucoup d'overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
