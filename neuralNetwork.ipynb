{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# H1N1 - Flu Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import reciprocal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def numerical_impute(data, numerical_list):\n",
    "    imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "    data_numerical = data.loc[:, numerical_list]\n",
    "    data_numerical_imputed = imputer_numerical.fit_transform(data_numerical)\n",
    "    data_numerical_imputed = pd.DataFrame(data_numerical_imputed, columns=numerical_list)\n",
    "    return data_numerical_imputed\n",
    "\n",
    "def categorical_imputing(data, categorical_list):\n",
    "    # Imputing\n",
    "    imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "    data_categorical = data.loc[:, categorical_list]\n",
    "    data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "    data_categorical_imputed = pd.DataFrame(data_categorical, columns=categorical_list)\n",
    "    return data_categorical_imputed\n",
    "\n",
    "def categorical_impute_one_hot(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # One hot encoding\n",
    "    data_one_hot = pd.get_dummies(data_categorical_imputed)\n",
    "\n",
    "    return data_one_hot\n",
    "\n",
    "def categorical_impute_ordinal(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical_imputed = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_ordinal = ordinal_encoder.fit_transform(data_categorical_imputed)\n",
    "    data_ordinal = pd.DataFrame(data_ordinal, columns=categorical_list)\n",
    "\n",
    "    return data_ordinal\n",
    "\n",
    "def categorical_impute_encode1(data, categorical_list):\n",
    "    # Imputing\n",
    "    data_categorical = categorical_imputing(data, categorical_list)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_categorical_encoded = ordinal_encoder.fit_transform(data_categorical)\n",
    "    data_categorical_encoded = pd.DataFrame(data_categorical_encoded, columns=categorical_list)\n",
    "\n",
    "    return data_categorical_encoded\n",
    "\n",
    "def categorical_impute_encode2(data, categorical_list_one_hot, categorical_list_ordinal):\n",
    "    # Imputing\n",
    "    data_categorical = categorical_imputing(data, categorical_list_ordinal + categorical_list_one_hot)\n",
    "\n",
    "    # Ordinal encoding\n",
    "    ordinal_encoder = OrdinalEncoder()\n",
    "    data_categorical_ordinal = ordinal_encoder.fit_transform(data_categorical.loc[:, categorical_list_ordinal])\n",
    "    data_categorical_ordinal = pd.DataFrame(data_categorical_ordinal, columns=categorical_list_ordinal)\n",
    "\n",
    "    # One hot encoding\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "    data_categorical_one_hot = one_hot_encoder.fit_transform(data_categorical.loc[:, categorical_list_one_hot])\n",
    "    data_categorical_one_hot = pd.DataFrame(data_categorical_one_hot, columns=categorical_list_one_hot)\n",
    "\n",
    "    data_categorical_encoded = pd.merge(data_categorical_ordinal, data_categorical_one_hot, left_index=True, right_index=True)\n",
    "\n",
    "    return data_categorical_encoded\n",
    "\n",
    "def data_clean(data, numerical_list, categorical_list, encoding='one_hot'):\n",
    "    # Changer les listes de features et les fonctions correspondantes\n",
    "    if encoding == 'ordinal':\n",
    "        data_categorical_encoded = categorical_impute_ordinal(data, categorical_list)\n",
    "    else :\n",
    "        data_categorical_encoded = categorical_impute_one_hot(data, categorical_list)\n",
    "    data_numerical_imputed = numerical_impute(data, numerical_list)\n",
    "    data_imputed_encoded = pd.merge(data_numerical_imputed, data_categorical_encoded, left_index=True, right_index=True)\n",
    "    \n",
    "    return data_imputed_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import des données\n",
    "==========="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26615 non-null  float64\n",
      " 1   h1n1_knowledge               26591 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 3   behavioral_avoidance         26499 non-null  float64\n",
      " 4   behavioral_face_mask         26688 non-null  float64\n",
      " 5   behavioral_wash_hands        26665 non-null  float64\n",
      " 6   behavioral_large_gatherings  26620 non-null  float64\n",
      " 7   behavioral_outside_home      26625 non-null  float64\n",
      " 8   behavioral_touch_face        26579 non-null  float64\n",
      " 9   doctor_recc_h1n1             24547 non-null  float64\n",
      " 10  doctor_recc_seasonal         24547 non-null  float64\n",
      " 11  chronic_med_condition        25736 non-null  float64\n",
      " 12  child_under_6_months         25887 non-null  float64\n",
      " 13  health_worker                25903 non-null  float64\n",
      " 14  health_insurance             14433 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 16  opinion_h1n1_risk            26319 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 19  opinion_seas_risk            26193 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 21  age_group                    26707 non-null  object \n",
      " 22  education                    25300 non-null  object \n",
      " 23  race                         26707 non-null  object \n",
      " 24  sex                          26707 non-null  object \n",
      " 25  income_poverty               22284 non-null  object \n",
      " 26  marital_status               25299 non-null  object \n",
      " 27  rent_or_own                  24665 non-null  object \n",
      " 28  employment_status            25244 non-null  object \n",
      " 29  hhs_geo_region               26707 non-null  object \n",
      " 30  census_msa                   26707 non-null  object \n",
      " 31  household_adults             26458 non-null  float64\n",
      " 32  household_children           26458 non-null  float64\n",
      " 33  employment_industry          13377 non-null  object \n",
      " 34  employment_occupation        13237 non-null  object \n",
      " 35  h1n1_vaccine                 26707 non-null  int64  \n",
      " 36  seasonal_vaccine             26707 non-null  int64  \n",
      "dtypes: float64(23), int64(2), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "FEATURES_TRAINING_PATH = \"training_set_features.csv\"\n",
    "LABELS_TRAINING_PATH = \"training_set_labels.csv\"\n",
    "\n",
    "features = pd.read_csv(FEATURES_TRAINING_PATH, sep=\",\", header=0)\n",
    "labels = pd.read_csv(LABELS_TRAINING_PATH, sep=\",\", header=0)\n",
    "data_original = pd.merge(features, labels, on=\"respondent_id\")\n",
    "respondent_id = data_original.loc[:, ['respondent_id']]\n",
    "data_original.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "data = data_original.copy()\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Liste des attributs\n",
    "-------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "arg_list = list(data.keys())\n",
    "features_list = arg_list.copy()\n",
    "features_list.remove(\"h1n1_vaccine\")\n",
    "features_list.remove(\"seasonal_vaccine\")\n",
    "\n",
    "labels_list = ['h1n1_vaccine', 'seasonal_vaccine']\n",
    "\n",
    "categorical_list = ['age_group', 'education', 'race', 'sex', 'income_poverty', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa','employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_one_hot = ['race', 'sex', 'marital_status', 'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa', 'employment_industry', 'employment_occupation']\n",
    "\n",
    "categorical_list_ordinal = [k for k in categorical_list if k not in categorical_list_one_hot]\n",
    "\n",
    "numerical_list = [k for k in features_list if k not in categorical_list]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On sauvegarde les listes de label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['lists.save']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fichier_sauvegarde_listes = 'lists.save'\n",
    "dic_label = {\n",
    "    'numerical_list' : numerical_list,\n",
    "    'categorical_list' : categorical_list,\n",
    "}\n",
    "joblib.dump(dic_label, fichier_sauvegarde_listes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "{'numerical_list': ['h1n1_concern',\n  'h1n1_knowledge',\n  'behavioral_antiviral_meds',\n  'behavioral_avoidance',\n  'behavioral_face_mask',\n  'behavioral_wash_hands',\n  'behavioral_large_gatherings',\n  'behavioral_outside_home',\n  'behavioral_touch_face',\n  'doctor_recc_h1n1',\n  'doctor_recc_seasonal',\n  'chronic_med_condition',\n  'child_under_6_months',\n  'health_worker',\n  'health_insurance',\n  'opinion_h1n1_vacc_effective',\n  'opinion_h1n1_risk',\n  'opinion_h1n1_sick_from_vacc',\n  'opinion_seas_vacc_effective',\n  'opinion_seas_risk',\n  'opinion_seas_sick_from_vacc',\n  'household_adults',\n  'household_children'],\n 'categorical_list': ['age_group',\n  'education',\n  'race',\n  'sex',\n  'income_poverty',\n  'marital_status',\n  'rent_or_own',\n  'employment_status',\n  'hhs_geo_region',\n  'census_msa',\n  'employment_industry',\n  'employment_occupation']}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists = joblib.load(\"lists.save\")\n",
    "lists"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "imputer_categorical = SimpleImputer(strategy='constant', fill_value='missing', missing_values=np.nan)\n",
    "data_categorical = data.loc[:, categorical_list]\n",
    "data_categorical = imputer_categorical.fit_transform(data_categorical)\n",
    "data_categorical = pd.DataFrame(data_categorical, columns=categorical_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 12 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   age_group              26707 non-null  float64\n",
      " 1   education              26707 non-null  float64\n",
      " 2   race                   26707 non-null  float64\n",
      " 3   sex                    26707 non-null  float64\n",
      " 4   income_poverty         26707 non-null  float64\n",
      " 5   marital_status         26707 non-null  float64\n",
      " 6   rent_or_own            26707 non-null  float64\n",
      " 7   employment_status      26707 non-null  float64\n",
      " 8   hhs_geo_region         26707 non-null  float64\n",
      " 9   census_msa             26707 non-null  float64\n",
      " 10  employment_industry    26707 non-null  float64\n",
      " 11  employment_occupation  26707 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "data_categorical_encoded = ordinal_encoder.fit_transform(data_categorical)\n",
    "data_categorical_encoded = pd.DataFrame(data_categorical_encoded, columns=categorical_list)\n",
    "data_categorical_encoded.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 23 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26707 non-null  float64\n",
      " 1   h1n1_knowledge               26707 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26707 non-null  float64\n",
      " 3   behavioral_avoidance         26707 non-null  float64\n",
      " 4   behavioral_face_mask         26707 non-null  float64\n",
      " 5   behavioral_wash_hands        26707 non-null  float64\n",
      " 6   behavioral_large_gatherings  26707 non-null  float64\n",
      " 7   behavioral_outside_home      26707 non-null  float64\n",
      " 8   behavioral_touch_face        26707 non-null  float64\n",
      " 9   doctor_recc_h1n1             26707 non-null  float64\n",
      " 10  doctor_recc_seasonal         26707 non-null  float64\n",
      " 11  chronic_med_condition        26707 non-null  float64\n",
      " 12  child_under_6_months         26707 non-null  float64\n",
      " 13  health_worker                26707 non-null  float64\n",
      " 14  health_insurance             26707 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26707 non-null  float64\n",
      " 16  opinion_h1n1_risk            26707 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26707 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26707 non-null  float64\n",
      " 19  opinion_seas_risk            26707 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26707 non-null  float64\n",
      " 21  household_adults             26707 non-null  float64\n",
      " 22  household_children           26707 non-null  float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "imputer_numerical = SimpleImputer(strategy='constant', fill_value=-1, missing_values=np.nan)\n",
    "data_numerical = data.loc[:, numerical_list]\n",
    "data_numerical = imputer_numerical.fit_transform(data_numerical)\n",
    "data_numerical = pd.DataFrame(data_numerical, columns=numerical_list)\n",
    "data_numerical.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data_encoded = pd.merge(data_numerical, data_categorical_encoded, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep learning classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modèle Simple\n",
    "==============="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On veut déterminer les probabilités d'appartenance à chaque classe : multilabel classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "data_encoded = data_clean(data, numerical_list, categorical_list, encoding='one_hot')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "labels.drop(\"respondent_id\", axis=1, inplace=True)\n",
    "Y = labels.to_numpy()\n",
    "X = data_encoded.to_numpy()\n",
    "\n",
    "shape_train_data = X.shape[1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1, test_size=0.2)\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, random_state=1, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On scale les données :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(17092, 112)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(17092, 2)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sauvegarde du scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['scaler.save']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, \"scaler.save\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modèle séquentiel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "n_neurons = 35\n",
    "dropout = 0.4\n",
    "n_layers = 3\n",
    "learning_rate = 3e-3\n",
    "model_seq = Sequential()\n",
    "model_seq.add(Input(shape=shape_train_data))\n",
    "for layer in range(n_layers):\n",
    "    model_seq.add(Dense(n_neurons, activation=\"relu\"))\n",
    "    model_seq.add(Dropout(dropout))\n",
    "model_seq.add(Dense(2, activation=\"sigmoid\"))\n",
    "optimizer = keras.optimizers.Adam()\n",
    "model_seq.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['AUC'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modèle fonctionnel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# modele assez performant : on peut modifier la structure en ajoutant une voie annexe par ex\n",
    "input_ = keras.layers.Input(shape=shape_train_data)\n",
    "hidden1 = keras.layers.Dense(35, activation=\"relu\")(input_)\n",
    "dropout1 = keras.layers.Dropout(0.5)(hidden1)\n",
    "hidden2 = keras.layers.Dense(15, activation=\"relu\")(dropout1)\n",
    "output = keras.layers.Dense(2, activation=\"sigmoid\")(hidden2)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On set up un callback de checkpoint et un early stopping :"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrainnement du modèle séquentiel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "535/535 [==============================] - 2s 2ms/step - loss: 0.6130 - auc: 0.6753 - val_loss: 0.5139 - val_auc: 0.8135\n",
      "Epoch 2/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.5248 - auc: 0.7888 - val_loss: 0.4699 - val_auc: 0.8425\n",
      "Epoch 3/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4926 - auc: 0.8164 - val_loss: 0.4571 - val_auc: 0.8533\n",
      "Epoch 4/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4795 - auc: 0.8281 - val_loss: 0.4433 - val_auc: 0.8573\n",
      "Epoch 5/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4684 - auc: 0.8375 - val_loss: 0.4438 - val_auc: 0.8590\n",
      "Epoch 6/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4637 - auc: 0.8414 - val_loss: 0.4424 - val_auc: 0.8605\n",
      "Epoch 7/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4566 - auc: 0.8471 - val_loss: 0.4367 - val_auc: 0.8630\n",
      "Epoch 8/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4557 - auc: 0.8475 - val_loss: 0.4348 - val_auc: 0.8646\n",
      "Epoch 9/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4514 - auc: 0.8506 - val_loss: 0.4238 - val_auc: 0.8668\n",
      "Epoch 10/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4466 - auc: 0.8535 - val_loss: 0.4251 - val_auc: 0.8679\n",
      "Epoch 11/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4441 - auc: 0.8552 - val_loss: 0.4208 - val_auc: 0.8686\n",
      "Epoch 12/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4430 - auc: 0.8563 - val_loss: 0.4218 - val_auc: 0.8698\n",
      "Epoch 13/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4421 - auc: 0.8570 - val_loss: 0.4184 - val_auc: 0.8707\n",
      "Epoch 14/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4365 - auc: 0.8607 - val_loss: 0.4209 - val_auc: 0.8702\n",
      "Epoch 15/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4370 - auc: 0.8609 - val_loss: 0.4210 - val_auc: 0.8702\n",
      "Epoch 16/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4355 - auc: 0.8609 - val_loss: 0.4202 - val_auc: 0.8712\n",
      "Epoch 17/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4367 - auc: 0.8610 - val_loss: 0.4186 - val_auc: 0.8718\n",
      "Epoch 18/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4341 - auc: 0.8627 - val_loss: 0.4170 - val_auc: 0.8718\n",
      "Epoch 19/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4315 - auc: 0.8640 - val_loss: 0.4153 - val_auc: 0.8718\n",
      "Epoch 20/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4311 - auc: 0.8643 - val_loss: 0.4166 - val_auc: 0.8714\n",
      "Epoch 21/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4299 - auc: 0.8645 - val_loss: 0.4182 - val_auc: 0.8705\n",
      "Epoch 22/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4305 - auc: 0.8651 - val_loss: 0.4175 - val_auc: 0.8718\n",
      "Epoch 23/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4256 - auc: 0.8683 - val_loss: 0.4145 - val_auc: 0.8727\n",
      "Epoch 24/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4298 - auc: 0.8653 - val_loss: 0.4158 - val_auc: 0.8723\n",
      "Epoch 25/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4272 - auc: 0.8664 - val_loss: 0.4131 - val_auc: 0.8735\n",
      "Epoch 26/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4253 - auc: 0.8687 - val_loss: 0.4142 - val_auc: 0.8729\n",
      "Epoch 27/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4257 - auc: 0.8678 - val_loss: 0.4131 - val_auc: 0.8734\n",
      "Epoch 28/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4250 - auc: 0.8686 - val_loss: 0.4153 - val_auc: 0.8724\n",
      "Epoch 29/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4274 - auc: 0.8673 - val_loss: 0.4143 - val_auc: 0.8727\n",
      "Epoch 30/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4215 - auc: 0.8712 - val_loss: 0.4142 - val_auc: 0.8726\n",
      "Epoch 31/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4233 - auc: 0.8701 - val_loss: 0.4158 - val_auc: 0.8721\n",
      "Epoch 32/100\n",
      "535/535 [==============================] - 1s 1ms/step - loss: 0.4213 - auc: 0.8713 - val_loss: 0.4153 - val_auc: 0.8722\n",
      "Epoch 33/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4216 - auc: 0.8711 - val_loss: 0.4158 - val_auc: 0.8721\n",
      "Epoch 34/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4216 - auc: 0.8708 - val_loss: 0.4148 - val_auc: 0.8720\n",
      "Epoch 35/100\n",
      "535/535 [==============================] - 1s 2ms/step - loss: 0.4213 - auc: 0.8712 - val_loss: 0.4147 - val_auc: 0.8721\n"
     ]
    }
   ],
   "source": [
    "history_seq = model_seq.fit(X_train_scaled, Y_train, batch_size=32, epochs=100, validation_data=(X_valid_scaled, Y_valid), callbacks=[checkpoint_cb, early_stopping_cb], verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrainnement du modèle fonctionnel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2980/2963647942.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_valid_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_valid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcheckpoint_cb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mearly_stopping_cb\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train, epochs=100, validation_data=(X_valid_scaled, Y_valid), callbacks=[checkpoint_cb, early_stopping_cb], verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On récupère le meilleur modèle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "best_model_ever = keras.models.load_model(\"best_model_ever_8_12_2021.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "Y_pred = model_seq.predict(X_test_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "Y_pred_best = best_model_ever.predict(X_test_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model :  0.85896695070634\n"
     ]
    }
   ],
   "source": [
    "print(\"model : \", roc_auc_score(Y_test, Y_pred)) # C'est la mesure utilisée par DrivenData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"best model : \", roc_auc_score(Y_test, Y_pred_best))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yeahhhh score de 85,97% c'est top ! Objectif : 86.6%\n",
    "Malheureusement, le score sur driven data est moins important et vaut seulement 84.5%, donc il y a de la marge de progrès !"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Points d'amélioration :\n",
    "* A voir si en enlevant des données manquantes on ne peut pas encore améliorer le score\n",
    "* Il faudrait essayer le feature engineering\n",
    "* On peut utiliser un OneHot encoder pour certaines données catégorielles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine tuning Neural Network Hyperparameters\n",
    "========="
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Possible to use :\n",
    "* RandomizedSearchCV from scikit learn with some wrapper\n",
    "* Keras tuner from tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikeras and RandomizedSearchCV\n",
    "--------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, hidden_layer_sizes=30, learning_rate=3e-3, input_shape=[35]):\n",
    "    model = Sequential()\n",
    "    model.add(Input(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(Dense(hidden_layer_sizes, activation=\"relu\"))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"binary_cross_entropy\", optimizer=optimizer)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "keras_model = KerasClassifier(build_model, epochs=100, callbacks=[early_stopping_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden' : [0,1,2,3],\n",
    "    'hidden_layer_sizes' : list(range(1,100)),\n",
    "    'optimizer__learning_rate' : [3e-4, 3e-3, 3e-2]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter n_neurons for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(n_neurons=41)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2980/1046971999.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mrnd_search_cv\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mRandomizedSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkeras_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_distribs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_iter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscoring\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'roc_auc'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mrnd_search_cv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_valid_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY_valid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    889\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    890\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 891\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    892\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1764\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1765\u001B[0m         \u001B[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1766\u001B[1;33m         evaluate_candidates(\n\u001B[0m\u001B[0;32m   1767\u001B[0m             ParameterSampler(\n\u001B[0;32m   1768\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_state\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom_state\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    836\u001B[0m                     )\n\u001B[0;32m    837\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 838\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    839\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    840\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;31m# remaining jobs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1043\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1044\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1045\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    859\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    860\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 861\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    862\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    863\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    777\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    778\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 779\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    780\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    781\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    570\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 572\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    573\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    574\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    260\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 262\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    263\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    264\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    667\u001B[0m             \u001B[0mcloned_parameters\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msafe\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    668\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 669\u001B[1;33m         \u001B[0mestimator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset_params\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mcloned_parameters\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    670\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m     \u001B[0mstart_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\romai\\documents\\projets\\lib\\site-packages\\scikeras\\wrappers.py\u001B[0m in \u001B[0;36mset_params\u001B[1;34m(self, **params)\u001B[0m\n\u001B[0;32m   1125\u001B[0m                     \u001B[1;31m# Give a SciKeras specific user message to aid\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1126\u001B[0m                     \u001B[1;31m# in moving from the Keras wrappers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1127\u001B[1;33m                     raise ValueError(\n\u001B[0m\u001B[0;32m   1128\u001B[0m                         \u001B[1;34mf\"Invalid parameter {param} for estimator {self.__name__}.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1129\u001B[0m                         \u001B[1;34m\"\\nThis issue can likely be resolved by setting this parameter\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid parameter n_neurons for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(n_neurons=41)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_model, param_distribs, n_iter=10, cv=3, scoring='roc_auc')\n",
    "rnd_search_cv.fit(X_train_scaled, Y_train, validation_data=(X_valid_scaled, Y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikeras un peu chiant à utiliser et pas super bien documenté"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Keras Tuner\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import Hyperband"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class ClassificationHyperModel(HyperModel):\n",
    "    \"\"\" Keras HyperModel applied to the classification model to put the search space together \"\"\"\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Defining the hyperparameters to thune\n",
    "        nb_layers = hp.Int('n_layers', min_value=1, max_value=15, step=1, default=3)\n",
    "        nb_neurons = hp.Int('n_neurons', min_value=10, max_value=300, default=30)\n",
    "        dropout_rate = hp.Float('rate', min_value=0, max_value=0.9, default=0.5, step=0.1)\n",
    "        learning_rate = hp.Float('learnin_rate', min_value=1e-4, max_value=1e-2, default=1e-3, sampling='LOG')\n",
    "\n",
    "        # Building the model structure\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=self.input_shape))\n",
    "        for layer in range(nb_layers):\n",
    "            model.add(Dense(units=nb_neurons, activation=\"relu\"))\n",
    "            model.add(Dropout(rate=dropout_rate))\n",
    "        model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate), metrics=['AUC'])\n",
    "\n",
    "        return model\n",
    "\n",
    "hypermodel = ClassificationHyperModel(input_shape=shape_train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=40,\n",
    "    objective=kt.Objective('val_auc', direction='max'),\n",
    "    executions_per_trial=2,\n",
    "    seed=1,\n",
    "    directory='Keras-tuning',\n",
    "    project_name='neuralNetwork'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 01m 15s]\n",
      "val_auc: 0.8617083430290222\n",
      "\n",
      "Best val_auc So Far: 0.8694462180137634\n",
      "Total elapsed time: 00h 36m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled, Y_train, validation_split=0.2, epochs=40, callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in Keras-tuning\\neuralNetwork\n",
      "Showing 10 best trials\n",
      "Objective(name='val_auc', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 4\n",
      "n_neurons: 236\n",
      "rate: 0.30000000000000004\n",
      "learnin_rate: 0.00013414267455355165\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: ebcccdd5539913b002832ab11bc5ee77\n",
      "Score: 0.8694462180137634\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 62\n",
      "rate: 0.2\n",
      "learnin_rate: 0.003098269932407016\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 3f2518980de84cf0204b939c8bc779a6\n",
      "Score: 0.8689286708831787\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 62\n",
      "rate: 0.2\n",
      "learnin_rate: 0.003098269932407016\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.8688881099224091\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "n_neurons: 178\n",
      "rate: 0.2\n",
      "learnin_rate: 0.00041268008323824807\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 5ee4cae8932fb95d5ff1ec1653ac29df\n",
      "Score: 0.8688600957393646\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 4\n",
      "n_neurons: 236\n",
      "rate: 0.30000000000000004\n",
      "learnin_rate: 0.00013414267455355165\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8682965934276581\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 1\n",
      "n_neurons: 62\n",
      "rate: 0.2\n",
      "learnin_rate: 0.003098269932407016\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 95c9761ca72a170c4cbfa632e923a3f4\n",
      "Score: 0.8682909905910492\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "n_neurons: 287\n",
      "rate: 0.2\n",
      "learnin_rate: 0.0002965488058019691\n",
      "tuner/epochs: 14\n",
      "tuner/initial_epoch: 5\n",
      "tuner/bracket: 3\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 4c7fb39320fbd9e6d64812119375f820\n",
      "Score: 0.868184357881546\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 2\n",
      "n_neurons: 178\n",
      "rate: 0.2\n",
      "learnin_rate: 0.00041268008323824807\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: ebf2e1e231e891d3061c87f597ed662b\n",
      "Score: 0.8681538701057434\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 3\n",
      "n_neurons: 287\n",
      "rate: 0.2\n",
      "learnin_rate: 0.0002965488058019691\n",
      "tuner/epochs: 40\n",
      "tuner/initial_epoch: 14\n",
      "tuner/bracket: 3\n",
      "tuner/round: 3\n",
      "tuner/trial_id: b11f67666cd4b478b630dc11fd223a25\n",
      "Score: 0.867611438035965\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_layers: 4\n",
      "n_neurons: 240\n",
      "rate: 0.1\n",
      "learnin_rate: 0.0006237028864858578\n",
      "tuner/epochs: 5\n",
      "tuner/initial_epoch: 2\n",
      "tuner/bracket: 3\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 7b86e3742992715e57a648ff64218536\n",
      "Score: 0.8673843443393707\n"
     ]
    }
   ],
   "source": [
    "# Show summary of the results\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8570719932365425\n"
     ]
    }
   ],
   "source": [
    "Y_pred = best_model.predict(X_test_scaled)\n",
    "print(roc_auc_score(Y_test, Y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "best_model.save('model_hypertunned.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Best three models after tunning\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def create_model(input_shape, nb_layers, nb_neurons, dropout_rate, learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    for layer in range(nb_layers):\n",
    "        model.add(Dense(units=nb_neurons, activation=\"relu\"))\n",
    "        model.add(Dropout(rate=dropout_rate))\n",
    "    model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate), metrics=['AUC'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "top_three_parameters = [\n",
    "    {\n",
    "        'nb_layers' : 4,\n",
    "        'nb_neurons' : 236,\n",
    "        'dropout_rate' : 0.3,\n",
    "        'learning_rate' : 0.0001341426\n",
    "    },\n",
    "    {\n",
    "        'nb_layers' : 1,\n",
    "        'nb_neurons' : 62,\n",
    "        'dropout_rate' : 0.2,\n",
    "        'learning_rate' : 0.00309826\n",
    "    },\n",
    "    {\n",
    "        'nb_layers' : 2,\n",
    "        'nb_neurons' : 178,\n",
    "        'dropout_rate' : 0.2,\n",
    "        'learning_rate' : 0.000412680\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "best_three_models = []\n",
    "for parameters in top_three_parameters:\n",
    "    best_three_models.append(create_model(shape_train_data, parameters['nb_layers'], parameters['nb_neurons'], parameters['dropout_rate'], parameters['learning_rate']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "for model in best_three_models:\n",
    "    model.fit(X_train_scaled, Y_train, epochs=40, validation_data=(X_valid_scaled, Y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)], verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score :  0.8045863124923993\n",
      "ROCAUC score :  0.8223497087478446\n",
      "ROCAUC score :  0.8019032995921855\n"
     ]
    }
   ],
   "source": [
    "for model in best_three_models:\n",
    "    Y_pred = model.predict(X_test)\n",
    "    print(\"ROCAUC score : \", roc_auc_score(Y_test, Y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Résultats assez décevant, il fallait probablement utiliser plus de données pour commencer ou augmenter l'espace de recherche :\n",
    "\n",
    "Résultats obtenus pour 36 min de recherche :\n",
    "* ROCAUC score :  0.8043674994274905\n",
    "* ROCAUC score :  0.816739745544371\n",
    "* ROCAUC score :  0.8113774287104558\n",
    "\n",
    "La recherche s'est terminée par \"oracle triggered exit\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}